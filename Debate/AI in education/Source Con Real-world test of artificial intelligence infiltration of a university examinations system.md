Title: A real-world test of artificial intelligence infiltration of a university examinations system: A “Turing Test” case study
Link: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0305354
Citation: 
> [!note] Citation
> ## Scarfe et al. 2024
> Scarfe, Peter, Kelly Watcham, Alasdair Clarke, and Etienne Roesch. “A Real-World Test of Artificial Intelligence Infiltration of a University Examinations System: A ‘Turing Test’ Case Study.” _PLOS ONE_ 19, no. 6 (June 26, 2024): e0305354. [https://doi.org/10.1371/journal.pone.0305354](https://doi.org/10.1371/journal.pone.0305354).

# Abstract

The recent rise in artificial intelligence systems, such as ChatGPT, poses a fundamental problem for the educational sector. In universities and schools, many forms of assessment, such as coursework, are completed without invigilation. Therefore, students could hand in work as their own which is in fact completed by AI. Since the COVID pandemic, the sector has additionally accelerated its reliance on unsupervised ‘take home exams’. If students cheat using AI and this is undetected, the integrity of the way in which students are assessed is threatened. We report a rigorous, blind study in which we injected 100% AI written submissions into the examinations system in five undergraduate modules, across all years of study, for a BSc degree in Psychology at a reputable UK university. We found that **94% of our AI submissions were undetected. The grades awarded to our AI submissions were on average half a grade boundary higher than that achieved by real students**. Across modules there was an 83.4% chance that the AI submissions on a module would outperform a random selection of the same number of real student submissions.