# Con AI bad learning

Admad et al. wrote in Nature in 2023 that 68.9% of laziness in humans, 68.6% in personal privacy and security issues, and 27.7% in the loss of decision-making are due to the impact of artificial intelligence in Pakistani and Chinese society.

According to Abbas et al. 2024, a survey of the effects of ChatGPT usage on university students showed that ChatGPT usage was correlated with future procrastination, memory loss, memory impairment, declining academic performance and low GPAs.

Bastani et al 2024. showed that in a study of UPenn students, when students are given AI for study but are tested without it, they actually perform worse, showing a 17% decline for GPT-4 and showing no improvement with a special tutor. 

Wecks et al. 2024 showed that students who used GenAI tools to write their essays scored 6.71 points out of a 100 lower than non-users on average. 

Ju 2023 found that in reading tasks, complete reliance on AI for writing tasks led to a 25.1% reduction in accuracy. In contrast, AI-assisted reading resulted in a 12% decline

Nie et al. 2024 found that in an online coding class, only 44.1% of the students given the AI tutor took the final exam, compared to 48.5% of the students in the control group. 






---

# Con AI deepfakes

In a report from the New York Times, there is a rise of deepfake nudes in schools, generating child sexual abuse material, used to harass female students. At Westfield High School in New Jersey, 10th grade girls found out that boys were distributing fake explicit photos of them. At Issaquah High School in Seattle, 14- and 15-year-old students complained about explicit A.I. generated deepfakes of them. At Beverly Vista Middle School in California, 5 boys were expelled from the school shortly after the school noticed that explicit deepfakes were being circulated among the community. A survey from the South Korean Ministry of Education found that 799 students and 31 teachers were victimized by deepfake videos so far in 2024. 

Child sexual exploitation experts say the use of nonconsensual, A.I.-generated images to harass, humiliate and bully young women can harm their mental health, reputations and physical safety as well as pose risks to their college and career prospects

---

# Con AI privacy

AI violates the privacy of its users. 

According to the 74 million, an education news publication, an AI app, Ed, that was used by the Los Angeles school district included students’ personally identifiable information in all chatbot prompts, which were shared with other third-party companies, and sent to other countries, exposing students’ information to potential cyberattacks and data breaches and subjecting it to foreign governments’ surveillance rules. An investigation found that the chatbot provided the student’s grades, progress toward graduation and other personal information, in violation of the school district’s data use agreement. 

---

# Pro AI can help increase access for minorities

Good teachers are scarce, especially in less resourced countries. Having a private tutor is a high cost that many people cannot afford. However, AIs are widely available to people from all places in the world as long as they have an internet connection, helping to lower barriers to education and allow more students to access education, especially in underserved regions. 

According to Nie et al. 2024, offering GPT access to students who are from low development countries had 14 percentage points more in exam participation rates compared to baseline. 

According to Henkel et al. 2024, giving students from Ghana access to an LLM to study math increased their scores more than the effect of a good teacher. The LLM tutor had an effect equivalent to moving the students up one grade level. 

According to Kabakoo, a platform teaching digital skills to people in Africa with AI-powered tutoring, they found that incomes increased 71% after the lessons and learners’ self-confidence increased by 47%. 22% of participating learners on Kabakoo didn’t finish high-school.



---

# Pro AI help learning

Nie et al. 2024 found that people in an online coding class who were given an AI tutor to learn from had a 6.8 percentage point increase in their exam course. 

Henkel et al. 2024 gave an AI-powered tutor on WhatsApp to students in Ghana, which worked with basic mobile devices on low-bandwidth data networks, improving scores of students who used it by 8.5% relative to control, with learning gains more than double of the control group. The service only costs $5 per student per year, a lot cheaper than tutors. 

Vanzo, Chowdhury and Sachan 2024 found that a tutor bot helped improve grades by 4.3 percentage points for students in the equivalent of 11th grade, with an effect size double of that of a good teacher (see Henkel et al. 2024 for good teacher reference). 100% of returning high-school students who used the homework tutor bot wanted to use it next year. 

Kabakoo 2024 found that an educational program with AI virtual mentors achieved a learning score of 1.9 18 months after completing the program, compared to 1.5 for the control group, showing a 27% increase.

Möller et al. 2024 found that an AI-powered exam studying feature increased progress scores of users by 46 percentage-points

A study of an AI tutoring bot for a Harvard physics course found that students given the AI tutor performed over double as well on their exams compared to control, with a 133% gain. 


---

# Pro AI help teachers



---

# Pro AI is optional

Generative AI is an tool that people can choose to use. Although there might be situations where it would struggle, people can simply decide not to use AI, so if AI would be harmful in that situation, we can just simply not use it there and only use it for use cases that it is good at. To prove that AI is harmful, the con side must prove that their argument stands even if the user decides not to use AI to help with that particular use case. 

---

# Resolution

Resolved: "**The benefits of the use of generative artificial intelligence in education outweigh the harms.**"

![[Definition Generative Artificial Intelligence#Generative artificial intelligence]]

---

# Definition Generative Artificial Intelligence

# Generative artificial intelligence

> **Generative artificial intelligence** (**generative AI**, **GenAI** or **GAI**) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to [prompts](https://en.wikipedia.org/wiki/Prompt_(natural_language) "Prompt (natural language)"). Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.

# Wikipedia page

<iframe src="https://en.wikipedia.org/wiki/Generative_artificial_intelligence" width=100% height=600px></iframe>


---

# List of arguments from ChatGPT

# Pro

Here is a list of arguments supporting the claim that the benefits of using generative artificial intelligence (AI) in education outweigh the harms:

### 1. Personalized Learning
   - Generative AI can create tailored educational content and experiences for individual learners, adapting to their specific needs, learning pace, and preferences. This personalized approach can improve learning outcomes and engagement.
  
### 2. Enhanced Access to Educational Resources
   - AI can generate accessible and high-quality learning materials (e.g., summaries, practice exercises, explanations) for a wide range of subjects. This democratizes education, providing more people access to resources, especially in underserved or resource-poor areas.
  
### 3. Time and Labor Efficiency for Educators
   - Generative AI can automate routine tasks like grading, generating lesson plans, and creating quizzes, freeing up time for educators to focus on higher-order activities such as one-on-one interactions, mentoring, and fostering critical thinking skills.

### 4. Immediate Feedback for Students
   - AI tools can provide instant feedback on student assignments and assessments, helping students to identify and correct mistakes in real time. This fosters continuous learning and improvement without the delays often associated with traditional feedback loops.

### 5. Support for Diverse Learning Styles
   - AI systems can generate multiple forms of content (text, video, simulations, etc.) that cater to different learning styles, whether auditory, visual, or kinesthetic. This inclusivity can improve student engagement and learning outcomes.
  
### 6. Cost-Effective Educational Solutions
   - Generative AI can help reduce the cost of developing educational materials, allowing institutions to offer high-quality content and resources at lower prices, making education more affordable and accessible.

### 7. Encouraging Creativity and Critical Thinking
   - By using AI tools to assist with projects, brainstorming, and problem-solving exercises, students are encouraged to explore creative approaches and think critically about information and ideas generated by AI, fostering deeper understanding and innovation.

### 8. Adaptive Tutoring and Remediation
   - AI-powered tutoring systems can identify student weaknesses and offer targeted remediation. These systems can adjust the difficulty and focus of the material based on individual performance, ensuring that no student is left behind.
  
### 9. Global Collaboration and Cultural Exposure
   - Generative AI facilitates cross-border collaboration by translating educational content and allowing students from different linguistic backgrounds to learn and work together. It opens up new opportunities for global learning and intercultural exchanges.
  
### 10. Fostering Lifelong Learning
   - With AI tools available at any time, learners can access educational resources beyond the classroom environment, encouraging self-directed, lifelong learning that fosters continuous skill development in a rapidly evolving world.

### 11. Support for Special Needs Education
   - AI can generate customized content or create specific accommodations (e.g., text-to-speech, simplified language, or visual aids) for students with learning disabilities or special needs, enabling more inclusive educational practices.

### 12. Innovation in Pedagogy and Curriculum Design
   - Generative AI can assist educators in designing innovative, interactive, and up-to-date curricula that integrate the latest advancements in technology, making education more engaging and relevant to the needs of the modern world.

### 13. Reduction of Teacher Burnout
   - By automating repetitive tasks, generative AI can help reduce teacher workloads, leading to less burnout and greater job satisfaction, allowing educators to focus on creative and impactful teaching practices.

### 14. Multilingual Support
   - AI can generate educational materials in multiple languages or provide real-time translation services, supporting non-native speakers in their learning and helping to bridge language barriers in global education settings.

### 15. Enhanced Research Opportunities
   - Generative AI can assist students and researchers in accessing, organizing, and analyzing large datasets, generating hypotheses, and conducting literature reviews, accelerating the pace of academic research and discovery.

In conclusion, while there are potential risks associated with AI in education, the benefits such as personalization, accessibility, efficiency, and enhanced learning opportunities demonstrate its positive potential when responsibly implemented.

---

# Source Con 799 students, 31 teachers victimized by deepfake videos this year

Title: 799 Students, 31 Teachers Victimized by Deepfake Videos This Year: Education Ministry.
Link: https://en.yna.co.kr/view/AEN20240930005500315
Citation:
> [!note] Citation
> ## Boram 2024
> Boram, Park. “799 Students, 31 Teachers Victimized by Deepfake Videos This Year: Education Ministry.” Yonhap News Agency, September 30, 2024. https://en.yna.co.kr/view/AEN20240930005500315.

A total of **799 students from elementary to high school have fallen victim to deepfake videos this year, along with 31 teachers**, a recent survey showed Monday.

The Ministry of Education disclosed the figures from its recent survey, revealing that 833 people were victimized by deepfake videos between Jan. 1 and Oct. 27, including three school employees.

During this period, 504 damage reports were filed with schools, including 279 from high schools and 209 from middle schools.

Of the total cases, 417 have been referred to authorities for investigation, including 223 from high schools, while 218 have been referred for deletion, the survey showed.

# Debate block
A survey from the South Korean Ministry of Education found that 799 students and 31 teachers were victimized by deepfake videos so far in 2024. 

---

# Source Con AI Detectors Falsely Accuse Students of Cheating—With Big Consequences

Title: AI Detectors Falsely Accuse Students of Cheating—With Big Consequences
Link: https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations
Citation: 
> [!note] Citation
> ## Davalos and Yin 2024
> Jackie Davalos and Leon Yin. “AI Detectors Falsely Accuse Students of Cheating—With Big Consequences.” _Bloomberg.Com_, October 18, 2024. https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations.

# Summary
The best AI writing detectors are highly accurate, but they’re not foolproof. _Businessweek_ tested two of the leading services—GPTZero and Copyleaks—on a random sample of 500 college application essays submitted to Texas A&M University in the summer of 2022, shortly before the release of ChatGPT, effectively guaranteeing they weren’t AI-generated. The essays were obtained through a public records request, meaning they weren’t part of the datasets on which AI tools are trained. _Businessweek_ found the services falsely flagged 1% to 2% of the essays as likely written by AI, in some cases claiming to have near 100% certainty.

3 essays flagged as AI, 9 essays flagged as part AI, part human, 488 essays flagged as human, total 500 essays analyzed

0.6% AI
2.4% mix of AI and human
97% human



---

# Source Con Artificial intelligence on human loss indecision making, laziness and safety in education

Title: Impact of artificial intelligence on human loss in decision making, laziness and safety in education
Link: https://www.nature.com/articles/s41599-023-01787-8
Citation:
> [!note] Citation
> ## Admad et al. 2023
> Ahmad, Sayed Fayaz, Heesup Han, Muhammad Mansoor Alam, Mohd Khairul Rehmat, Muhammad Irshad, Marcelo Arraño-Muñoz, and Antonio Ariza-Montes. “Impact of Artificial Intelligence on Human Loss in Decision Making, Laziness and Safety in Education.” _Humanities and Social Sciences Communications_ 10, no. 1 (June 9, 2023): 1–14. https://doi.org/10.1057/s41599-023-01787-8.

# Abstract
This study examines the impact of artificial intelligence (AI) on loss in decision-making, laziness, and privacy concerns among university students in Pakistan and China. Like other sectors, education also adopts AI technologies to address modern-day challenges. AI investment will grow to USD 253.82 million from 2021 to 2025. However, worryingly, researchers and institutions across the globe are praising the positive role of AI but ignoring its concerns. This study is based on qualitative methodology using PLS-Smart for the data analysis. Primary data was collected from 285 students from different universities in Pakistan and China. The purposive Sampling technique was used to draw the sample from the population. The data analysis findings show that AI significantly impacts the loss of human decision-making and makes humans lazy. It also impacts security and privacy. The findings show that **68.9% of laziness in humans, 68.6% in personal privacy and security issues, and 27.7% in the loss of decision-making are due to the impact of artificial intelligence in Pakistani and Chinese society.** From this, it was observed that human laziness is the most affected area due to AI. However, this study argues that significant preventive measures are necessary before implementing AI technology in education. Accepting AI without addressing the major human concerns would be like summoning the devils. Concentrating on justified designing and deploying and using AI for education is recommended to address the issue

The first direct relationship is between artificial intelligence to loss in human decision-making, with a beta value of 0.277. The beta value shows that one unit increase in artificial intelligence will lose human decision-making by 0.277 units among university students in Pakistan and China.

one unit increase in artificial intelligence will make the students of Pakistan and China universities lazy by 0.689 units.

a one-unit increase in artificial intelligence will increase security
and privacy issues by 0.686



---

# Source Con Causes and consequences of generative AI usage among university students

Title: Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students
Link: https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-024-00444-7
Citation:
> [!note] Citation
> ## Abbas et al. 2024
> Abbas, Muhammad, Farooq Ahmed Jam, and Tariq Iqbal Khan. “Is It Harmful or Helpful? Examining the Causes and Consequences of Generative AI Usage among University Students.” _International Journal of Educational Technology in Higher Education_ 21, no. 1 (February 2024): 1–22. https://doi.org/10.1186/s41239-024-00444-7.
# Abstract
While the discussion on generative artificial intelligence, such as ChatGPT, is making waves in academia and the popular press, there is a need for more insight into the use of ChatGPT among students and the potential harmful or beneficial consequences associated with its usage. Using samples from two studies, the current research examined the causes and consequences of ChatGPT usage among university students. Study 1 developed and validated an eight-item scale to measure ChatGPT usage by conducting a survey among university students (N = 165). Study 2 used a three-wave time-lagged design to collect data from university students (N = 494) to further validate the scale and test the study’s hypotheses. Study 2 also examined the effects of academic workload, academic time pressure, sensitivity to rewards, and sensitivity to quality on ChatGPT usage. Study 2 further examined the effects of ChatGPT usage on students’ levels of procrastination, memory loss, and academic performance. Study 1 provided evidence for the validity and reliability of the ChatGPT usage scale. Furthermore, study 2 revealed that when students faced higher academic workload and time pressure, they were more likely to use ChatGPT. In contrast, students who were sensitive to rewards were less likely to use ChatGPT. Not surprisingly, use of ChatGPT was likely to develop tendencies for procrastination and memory loss and dampen the students’ academic performance. Finally, academic workload, time pressure, and sensitivity to rewards had indirect effects on students’ outcomes through ChatGPT usage.

A study on the effects of ChatGPT usage on university students showed that **ChatGPT usage was correlated with future procrastination, memory loss, memory impairment, declining academic performance and low GPAs**. 

---

# Source Con Coding on Copilot 2023 Data Suggests Downward Pressure on Code Quality

Title: Coding on Copilot: 2023 Data Suggests Downward Pressure on Code Quality (Incl 2024 Projections)
Link: https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality
Citation:
> [!note] Citation
> ## GitClear 2024
> Harding, William, and Matthew Kloster. “Coding on Copilot: 2023 Data Suggests Downward Pressure on Code Quality (Incl 2024 Projections).” GitClear, January 16, 2024. https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality.

# Abstract
2023 marked the coming out party for GitHub Copilot. In less than two years’ time, the AI programming assistant shot from “prototype” to “cornerstone,” used by millions of developers across hundreds of thousands of businesses [1]. Its unprecedented growth defines a new era in “how code gets written.” 

GitHub has published several pieces of research on the growth and impact of AI on software development. Among their findings is that developers write code “55% faster” when using Copilot. This profusion of LLM-generated code begs the question: how does the code quality and maintainability compare to what would have been written by a human? Is it more similar to the careful, refined contributions of a Senior Developer, or more akin to the disjointed work of a short-term contractor? 

To investigate, GitClear collected 153 million changed lines of code, authored between January 2020 and December 2023 [A1]. This is the largest known database of highly structured code change data that has been used to evaluate code quality differences [A2]. 

We find disconcerting trends for maintainability. Code churn -- the percentage of lines that are reverted or updated less than two weeks after being authored -- is projected to double in 2024 compared to its 2021, pre-AI baseline. We further find that the percentage of "added code" and "copy/pasted code" is increasing in proportion to “updated,” “deleted,” and “moved” code. In this regard, code generated during 2023 more resembles an itinerant contributor, prone to violate the DRY-ness of the repos visited. 

We conclude with suggestions for managers seeking to maintain high code quality in spite of the momentum opposing that goal.

**Churn increased by 39% (Churn is defined by percentage of code which was reverted in less than 2 weeks)**

---

# Source Con Evaluation of Large Language Models STEM education and Gender Stereotypes

Title: Evaluation of Large Language Models: STEM education and Gender Stereotypes
Link: https://arxiv.org/abs/2406.10133
Citation: 
> [!note] Citation
> ## Due et al. 2024
> Due, Smilla, Sneha Das, Marianne Andersen, Berta Plandolit López, Sniff Andersen Nexø, and Line Clemmensen. “Evaluation of Large Language Models: STEM Education and Gender Stereotypes.” arXiv, June 14, 2024. https://doi.org/10.48550/arXiv.2406.10133.

# Abstract
Large Language Models (LLMs) have an increasing impact on our lives with use cases such as chatbots, study support, coding support, ideation, writing assistance, and more. Previous studies have revealed linguistic biases in pronouns used to describe professions or adjectives used to describe men vs women. These issues have to some degree been addressed in updated LLM versions, at least to pass existing tests. However, biases may still be present in the models, and repeated use of gender stereotypical language may reinforce the underlying assumptions and are therefore important to examine further. This paper investigates gender biases in LLMs in relation to educational choices through an open-ended, true to user-case experimental design and a quantitative analysis. We investigate the biases in the context of four different cultures, languages, and educational systems (English/US/UK, Danish/DK, Catalan/ES, and Hindi/IN) for ages ranging from 10 to 16 years, corresponding to important educational transition points in the different countries. **We find that there are significant and large differences in the ratio of STEM to non-STEM suggested education paths provided by chatGPT when using typical girl vs boy names to prompt lists of suggested things to become.** There are generally fewer STEM suggestions in the Danish, Spanish, and Indian context compared to the English. We also find subtle differences in the suggested professions, which we categorise and report.

---

# Source Con Generative AI Can Harm Learning

Name: Generative AI Can Harm Learning
Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486
Citation:
> [!info] Citation
> 
> ## Bastani et al. 2024
> 
> Bastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, and Rei Mariman. “Generative AI Can Harm Learning.” SSRN Scholarly Paper. Rochester, NY, July 15, 2024. https://doi.org/10.2139/ssrn.4895486.

# Abstract

Generative artificial intelligence (AI) is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. However, a key remaining question is how generative AI affects _learning_, namely, how humans acquire new skills as they perform tasks. This kind of skill learning is critical to long-term productivity gains, especially in domains where generative AI is fallible and human experts must check its outputs. We study the impact of generative AI, specifically OpenAI's GPT-4, on human learning in the context of math classes at a high school. In a field experiment involving nearly a thousand students, we have deployed and evaluated two GPT based tutors, one that mimics a standard ChatGPT interface (called GPT Base) and one with prompts designed to safeguard learning (called GPT Tutor). These tutors comprise about 15% of the curriculum in each of three grades. Consistent with prior work, our results show that **access to GPT-4 significantly improves performance (48% improvement for GPT Base and 127% for GPT Tutor)**. However, we additionally find that **when access is subsequently taken away, students actually perform worse than those who never had access (17% reduction for GPT Base)**. That is, access to GPT-4 can harm educational outcomes. These negative learning effects are **largely mitigated by the safeguards included in GPT Tutor**. Our results suggest that students attempt to use GPT-4 as a "crutch" during practice problem sessions, and when successful, perform worse on their own. Thus, to maintain long-term productivity, we must be cautious when deploying generative AI to ensure humans continue to learn critical skills.

---

# Source Con Generative AI Usage and Academic Performance

Name: Generative AI Usage and Academic Performance
Link: https://arxiv.org/abs/2404.19699

> [!info] Citation
> ## Wecks et. al 2024
> 
> Wecks, Janik Ole, Johannes Voshaar, Benedikt Jost Plate, and Jochen Zimmermann. “Generative AI Usage and Academic Performance.” arXiv, April 30, 2024. https://doi.org/10.48550/arXiv.2404.19699.
# Abstract

This study evaluates the impact of students' usage of generative artificial intelligence (GenAI) tools such as ChatGPT on their academic performance. We analyze student essays using GenAI detection systems to identify GenAI users among the cohort. Employing multivariate regression analysis, we find that **students using GenAI tools score on average 6.71 (out of 100) points lower than non-users**. While GenAI tools may offer benefits for learning and engagement, the way students actually use it correlates with diminished academic outcomes. Exploring the underlying mechanism, additional analyses show that the effect is particularly detrimental to students with high learning potential, suggesting an effect whereby GenAI tool usage hinders learning. Our findings provide important empirical evidence for the ongoing debate on the integration of GenAI in higher education and underscores the necessity for educators, institutions, and policymakers to carefully consider its implications for student performance.

---

# Source Con LA Schools’ Chatbot Misused Student Data as Tech Co. Crumbled

Title: Whistleblower: L.A. Schools’ Chatbot Misused Student Data as Tech Co. Crumbled
Link: https://www.the74million.org/article/whistleblower-l-a-schools-chatbot-misused-student-data-as-tech-co-crumbled/
Citation:
> [!note] Citation
> ## Keierleber 2024
> Keierleber, Mark. “Whistleblower: L.A. Schools’ Chatbot Misused Student Data as Tech Co. Crumbled,” July 1, 2024. https://www.the74million.org/article/whistleblower-l-a-schools-chatbot-misused-student-data-as-tech-co-crumbled/.

# Summary

Just weeks before the implosion of AllHere, an education technology company that had been showered with cash from venture capitalists and featured in glowing profiles by the business press, America’s second-largest school district was warned about problems with AllHere’s product.

As the eight-year-old startup rolled out Los Angeles Unified School District’s flashy new AI-driven chatbot — an animated sun named “Ed” that AllHere was hired to build for $6 million — a former company executive was sending emails to the district and others that Ed’s workings violated bedrock student data privacy principles.

Whiteley told officials the **app included students’ personally identifiable information in all chatbot prompts**, even in those where the data weren’t relevant. **Prompts containing students’ personal information were also shared with other third-party companies unnecessarily,** Whiteley alleges, and were processed on offshore servers. Seven out of eight Ed chatbot requests, he said, are sent to places like Japan, Sweden, the United Kingdom, France, Switzerland, Australia and Canada. 

Taken together, he argued the company’s practices ran afoul of data minimization principles, a standard cybersecurity practice that maintains that apps should collect and process the least amount of personal information necessary to accomplish a specific task. Playing fast and loose with the data, he said, unnecessarily **exposed students’ information to potential cyberattacks and data breaches and, in cases where the data were processed overseas, could subject it to foreign governments’ data access and surveillance rules**.

Chatbot source code that Whiteley shared with The 74 outlines how prompts are processed on foreign servers by a Microsoft AI service that integrates with ChatGPT. The LAUSD chatbot is directed to serve as a “friendly, concise customer support agent” that replies “using simple language a third grader could understand.” When querying the simple prompt “Hello,” the **chatbot provided the student’s grades, progress toward graduation and other personal information**. 

AllHere’s critical flaw, Whiteley said, is that senior executives “didn’t understand how to protect data.” 

“The issue is we’re sending data overseas, we’re sending too much data, and then the data were being logged by third parties,” he said, in violation of the district’s data use agreement. “The product worked, right, but it worked by cheating. It cheated by not doing things right the first time.”

# Debate block

An AI app, Ed, that was used by the LA United school district included students’ personally identifiable information in all chatbot prompts, which were also shared with other third-party companies, with information being sent to at least 7 different countries, exposing students’ information to potential cyberattacks and data breaches and subjecting it to foreign governments’ data access and surveillance rules. For example, an investigation found that the chatbot provided the student’s grades, progress toward graduation and other personal information,  in violation of the school district’s data use agreement. 

---

# Source Con LAUSD shelves its hyped AI chatbot to help students after collapse of firm that made it

Title: LAUSD shelves its hyped AI chatbot to help students after collapse of firm that made it
Link: https://www.latimes.com/california/story/2024-07-03/lausds-highly-touted-ai-chatbot-to-help-students-fails-to-deliver
Citation:
> [!note] Citation
> ## Blume et al. 2024
> Blume, Howard. “LAUSD Shelves Its Hyped AI Chatbot to Help Students after Collapse of Firm That Made It.” Los Angeles Times, July 3, 2024. https://www.latimes.com/california/story/2024-07-03/lausds-highly-touted-ai-chatbot-to-help-students-fails-to-deliver.

# Summary

A much vaunted AI chatbot — custom designed to help students thrive academically and parents navigate the complexities of Los Angeles public schools — has been turned off after the company that created it furloughed “the vast majority” of its staff.

The school district said it dropped its dealings with AllHere, the company that created “Ed,” the sun-shaped chatbot, after “we were notified of their financial collapse.” AllHere did not respond to an inquiry this week from The Times and the level of its operation is unclear.

Meanwhile, the district unplugged the chatbot — for which AllHere had been paid $3 million — on June 14, less than three months after unveiling the animated figure as an easy-to-use, conversational companion for students and a soon-to-be-indispensable guide for parents. “Ed” is both a chatbot, personified as a happy, round sun, and an online platform that attempts to put together in one portal student records, assignments, grades, academic recommendations and mental health referrals.

# Debate block
Ed, an AI chatbot meant to help teach students, shut down less than 3 months after being introduced by the LA United school district, after they spent 3 million dollars on buying the chatbot. AllHere, the company behind Ed, had struggled with financial issues and was forced to shut down almost all of its operations. 

---

# Source Con LLMs are Biased Teachers Evaluating LLM Bias in Personalized Education

Title: LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education
Link: https://arxiv.org/abs/2410.14012
Citation:
> [!note] Citation
> ## Weissburg et al. 2024
> Weissburg, Iain, Sathvika Anand, Sharon Levy, and Haewon Jeong. “LLMs Are Biased Teachers: Evaluating LLM Bias in Personalized Education.” arXiv, October 17, 2024. https://doi.org/10.48550/arXiv.2410.14012.

# Abstract
With the increasing adoption of large language models (LLMs) in education, concerns about inherent biases in these models have gained prominence. We evaluate LLMs for bias in the personalized educational setting, specifically focusing on the models' roles as "teachers". We reveal significant biases in how models generate and select educational content tailored to different demographic groups, including race, ethnicity, sex, gender, disability status, income, and national origin. We introduce and apply two bias score metrics--Mean Absolute Bias (MAB) and Maximum Difference Bias (MDB)--to analyze 9 open and closed state-of-the-art LLMs. Our experiments, which utilize over 17,000 educational explanations across multiple difficulty levels and topics, uncover that **models perpetuate both typical and inverted harmful stereotypes**.

# Some interesting stuff

![[Pasted image 20241101225133.png]]

5.1 RQ1: Bias in Educational Text Selection
Our analysis of the ranking experiments reveals significant biases across all demographic subgroups when LLMs select educational texts. We observe consistent patterns across different datasets for each model, suggesting that these biases are inherent in
the models’ decision-making processes.

Stereotype and Reverse Bias. Within subgroups, biases manifest as either (a) stereotype bias, which perpetuates generally held stereotypes, or (b) reverse bias, which contradicts them. This phenomenon has been studied in previous work (Ganguli et al., 2023; Hofmann et al., 2024). We note that both types of bias are harmful in our setting.

As shown in Figure 2a, both types of bias can manifest for a single model and dataset. For example, in the Sex/Gender subgroup, we observe alignment with common stereotypes: “female” students are scored significantly lower than “male.” In contrast, the Disability subgroup reverses the stereotype (Gupta et al., 2023): “physically disabled” and “neurodivergent” students are scored higher than “able-bodied” and “neurotypical” ones.

Overall Patterns. Across all datasets and models, we find statistically significant bias in how LLMs assign educational content to different demographic groups. The Friedman test results (p < 0.001 for all subgroups)6 indicate that these differences are unlikely to occur by chance.

For the primary models listed in Section 4.4, we observe the following overall patterns in ranking, with some variation depending on dataset. For Gemini 1.5 Pro and Llama 3.1 405B, we observe reverse biases across all subgroups. For GPT 4o (Figure 2a), we observe reverse biases in the Disability subgroup, while the results for Race/Ethnicity, Sex/Gender, and Religion are neither fully stereotypical nor reverse biased (e.g. male is scored higher than female, but not highest overall).

![[Pasted image 20241101225345.png]]

Bias chart for GPT4o

GPT4o has many biases:
- Recommended higher-level sources for physically disabled and neurodivergent people and lower-level sources for able-bodied people
- Recommended higher-level sources for  Christians, Muslims, Jewish, and Hindu, while recommending lower-level sources for agnostic people
- Recommending lower-level sources for low-income people while recommending higher-level sources for middle-income people. 

---

# Source Con Negative Impact of Generative AI on Scientific Learning Outcomes

Name: Experimental Evidence on Negative Impact of Generative AI on Scientific Learning Outcomes
Link: https://arxiv.org/abs/2311.05629
Citation:
> [!info] Citation
> ## Ju 2023
> 
> Ju, Qirui. “Experimental Evidence on Negative Impact of Generative AI on Scientific Learning Outcomes.” arXiv.org, September 23, 2023. https://arxiv.org/abs/2311.05629v1.

# Abstract 

In this study, I explored the impact of Generative AI on learning efficacy in academic reading materials using experimental methods. College-educated participants engaged in three cycles of reading and writing tasks. After each cycle, they responded to comprehension questions related to the material. After adjusting for background knowledge and demographic factors, **complete reliance on AI for writing tasks led to a 25.1% reduction in accuracy. In contrast, AI-assisted reading resulted in a 12% decline**. Interestingly, using AI for summarization significantly improved both quality and output. Accuracy exhibited notable variance in the AI-assisted section. Further analysis revealed that individuals with a robust background in the reading topic and superior reading/writing skills benefitted the most. I conclude the research by discussing educational policy implications, emphasizing the need for educators to warn students about the dangers of over-dependence on AI and provide guidance on its optimal use in educational settings.

---

# Source Con Real-world test of artificial intelligence infiltration of a university examinations system

Title: A real-world test of artificial intelligence infiltration of a university examinations system: A “Turing Test” case study
Link: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0305354
Citation: 
> [!note] Citation
> ## Scarfe et al. 2024
> Scarfe, Peter, Kelly Watcham, Alasdair Clarke, and Etienne Roesch. “A Real-World Test of Artificial Intelligence Infiltration of a University Examinations System: A ‘Turing Test’ Case Study.” _PLOS ONE_ 19, no. 6 (June 26, 2024): e0305354. https://doi.org/10.1371/journal.pone.0305354.

# Abstract

The recent rise in artificial intelligence systems, such as ChatGPT, poses a fundamental problem for the educational sector. In universities and schools, many forms of assessment, such as coursework, are completed without invigilation. Therefore, students could hand in work as their own which is in fact completed by AI. Since the COVID pandemic, the sector has additionally accelerated its reliance on unsupervised ‘take home exams’. If students cheat using AI and this is undetected, the integrity of the way in which students are assessed is threatened. We report a rigorous, blind study in which we injected 100% AI written submissions into the examinations system in five undergraduate modules, across all years of study, for a BSc degree in Psychology at a reputable UK university. We found that **94% of our AI submissions were undetected. The grades awarded to our AI submissions were on average half a grade boundary higher than that achieved by real students**. Across modules there was an 83.4% chance that the AI submissions on a module would outperform a random selection of the same number of real student submissions.

---

# Source Con Teen Girls Confront an Epidemic of Deepfake Nudes in Schools

Title: Teen Girls Confront an Epidemic of Deepfake Nudes in Schools
Link: https://www.nytimes.com/2024/04/08/technology/deepfake-ai-nudes-westfield-high-school.html
Citation:
> [!note] Citation
> ## Singer 2024
> Singer, Natasha. “Teen Girls Confront an Epidemic of Deepfake Nudes in Schools.” _The New York Times_, April 8, 2024, sec. Technology. https://www.nytimes.com/2024/04/08/technology/deepfake-ai-nudes-westfield-high-school.html.

# Summary
Using artificial intelligence, middle and high school students have fabricated explicit images of female classmates and shared the doctored pictures.

In October, **some 10th-grade girls at Westfield High School — including Ms. Mani’s 14-year-old daughter, Francesca — alerted administrators that boys in their class had used artificial intelligence software to fabricate sexually explicit images of them and were circulating the faked pictures**. Five months later, the Manis and other families say, the district has done little to publicly address the doctored images or update school policies to hinder exploitative A.I. use.

Boys in several states have used widely available “nudification” apps to pervert real, identifiable photos of their clothed female classmates, shown attending events like school proms, into graphic, convincing-looking images of the girls with exposed A.I.-generated breasts and genitalia. In some cases, boys shared the faked images in the school lunchroom, on the school bus or through group chats on platforms like Snapchat and Instagram, according to school and police reports.

Such digitally altered images — known as “deepfakes” or “deepnudes” — can have devastating consequences. **Child sexual exploitation experts say the use of nonconsensual, A.I.-generated images to harass, humiliate and bully young women can harm their mental health, reputations and physical safety as well as pose risks to their college and career prospects**. Last month, the Federal Bureau of Investigation warned that it is illegal to distribute computer-generated child sexual abuse material, including realistic-looking A.I.-generated images of identifiable minors engaging in sexually explicit conduct.

At Issaquah High School near Seattle last fall, a police detective investigating complaints from parents about explicit A.I.-generated images of their 14- and 15-year-old daughters asked an assistant principal why the school had not reported the incident to the police, according to a report from the Issaquah Police Department. The school official then asked “what was she supposed to report,” the police document said, prompting the detective to inform her that schools are required by law to report sexual abuse, including possible child sexual abuse material. The school subsequently reported the incident to Child Protective Services, the police report said. (The New York Times obtained the police report through a public-records request.)

At Beverly Vista Middle School in Beverly Hills, Calif., administrators contacted the police in February after learning that five boys had created and shared A.I.-generated explicit images of female classmates. Two weeks later, the school board approved the expulsion of five students, according to district documents. (The district said California’s education code prohibited it from confirming whether the expelled students were the students who had manufactured the images.)

# Debate block
Because of generative AI, there is a rise of deepfake nudes in schools, generating child sexual abuse material, used to harass female students. At Westfield High School in New Jersey, 10th grade girls found out that boys were distributing fake explicit photos of them. At Issaquah High School in Seattle, 14- and 15-year-old students complained about explicit A.I. generated deepfakes of them. At Beverly Vista Middle School in California, 5 boys were expelled from the school shortly after the school noticed that explicit deepfakes were being circulated among the community. 

---

# Source Con Turnitin marks one year anniversary of its AI writing detector

Title: Turnitin marks one year anniversary of its AI writing detector with millions of papers reviewed globally
Link: https://www.turnitin.com/press/press-detail_17793
Citation:
> [!note] Citation
> ## Turnitin 2024
> “Turnitin Marks One Year Anniversary of Its AI Writing Detector with Millions of Papers Reviewed Globally,” April 19, 2024. https://www.turnitin.com/press/press-detail_17793.

# Summary
Of the over 200 million papers reviewed,* Turnitin data shows:  
- Over 22 million (approximately 11 percent of over 200 million) have at least 20 percent AI writing present*  
- Over six million (approximately three percent of over 200 million) have at least 80 percent AI writing present*

Source Con AI Detectors Falsely Accuse Students of Cheating—With Big Consequences says that around 1% of essays are flagged as being written by AI as false positives and 3% were flagged as being part AI part human

If assuming 200 million papers and 2 million are false positives, 4 million papers have at least 80 percent AI writing present and are not false positives. 

If 6 million would be falsely flagged for being part AI part human, then deducting that, 8% of all papers had at least 20 percent AI writing present, or 16 million. 



---

# Source Con Unmasking academic cheating behavior in the artificial intelligence era

Title: Unmasking academic cheating behavior in the artificial intelligence era: Evidence from Vietnamese undergraduates
Link: https://link.springer.com/article/10.1007/s10639-024-12495-4
Citation:
> [!note] Citation
> ## Nguyen and Goto 2024
> Nguyen, Hung Manh, and Daisaku Goto. “Unmasking Academic Cheating Behavior in the Artificial Intelligence Era: Evidence from Vietnamese Undergraduates.” _Education and Information Technologies_ 29, no. 12 (August 1, 2024): 15999–25. https://doi.org/10.1007/s10639-024-12495-4.
## Abstract
The proliferation of artificial intelligence (AI) technology has brought both innovative opportunities and unprecedented challenges to the education sector. Although AI makes education more accessible and efficient, the intentional misuse of AI chatbots in facilitating academic cheating has become a growing concern. By using the indirect questioning technique via a list experiment to minimize social desirability bias, this research contributes to the ongoing dialog on academic integrity in the era of AI. Our findings reveal that students conceal AI-powered academic cheating behaviors when directly questioned, as the prevalence of cheaters observed via list experiments is almost threefold the prevalence of cheaters observed via the basic direct questioning approach. Interestingly, our subsample analysis shows that AI-powered academic cheating behaviors differ significantly across genders and grades, as higher-grade female students are more likely to cheat than newly enrolled female students. Conversely, male students consistently engage in academic cheating throughout all grades. Furthermore, we discuss potential reasons for the heterogeneous effects in academic cheating behavior among students such as gender disparity, academic-related pressure, and peer effects. Implications are also suggested for educational institutions to promote innovative approaches that harness the benefits of AI technologies while safeguarding academic integrity.

When directly asked, 9.6% of respondents say they have cheated with AI. When asked with a type of survey meant to preserve privacy, around 23.7% of respondents say that they have cheated with AI. 

---

# Source Idk Cognitive Network Science Reveals Bias in GPT-3, GPT-3.5 Turbo, and GPT-4 Mirroring Math Anxiety in High-School Students

Title: Cognitive Network Science Reveals Bias in GPT-3, GPT-3.5 Turbo, and GPT-4 Mirroring Math Anxiety in High-School Students
Link: https://www.mdpi.com/2504-2289/7/3/124
Citation:
> [!note] Citation
> ## Abramski et al. 2023
> Abramski, Katherine, Salvatore Citraro, Luigi Lombardi, Giulio Rossetti, and Massimo Stella. “Cognitive Network Science Reveals Bias in GPT-3, GPT-3.5 Turbo, and GPT-4 Mirroring Math Anxiety in High-School Students.” _Big Data and Cognitive Computing_ 7, no. 3 (2023). https://doi.org/10.3390/bdcc7030124.

# Abstract
Large Language Models (LLMs) are becoming increasingly integrated into our lives. Hence, it is important to understand the biases present in their outputs in order to avoid perpetuating harmful stereotypes, which originate in our own flawed ways of thinking. This challenge requires developing new benchmarks and methods for quantifying affective and semantic bias, keeping in mind that LLMs act as psycho-social mirrors that reflect the views and tendencies that are prevalent in society. One such tendency that has harmful negative effects is the global phenomenon of anxiety toward math and STEM subjects. In this study, we introduce a novel application of network science and cognitive psychology to understand biases towards math and STEM fields in LLMs from ChatGPT, such as GPT-3, GPT-3.5, and GPT-4. Specifically, we use behavioral forma mentis networks (BFMNs) to understand how these LLMs frame math and STEM disciplines in relation to other concepts. We use data obtained by probing the three LLMs in a language generation task that has previously been applied to humans. Our findings indicate that **LLMs have negative perceptions of math and STEM fields, associating math with negative concepts in 6 cases out of 10**. We observe significant differences across OpenAI’s models: **newer versions (i.e., GPT-4) produce 5× semantically richer, more emotionally polarized perceptions with fewer negative associations compared to older versions** and 𝑁=159 high-school students. These findings suggest that advances in the architecture of LLMs may lead to increasingly less biased models that could even perhaps someday aid in reducing harmful stereotypes in society rather than perpetuating them.

---

# Source Idk GenAI in Higher Education

Title: GenAI In Higher Education: Fall 2023 Update of Time for Class Study
Link: https://tytonpartners.com/app/uploads/2023/10/GenAI-IN-HIGHER-EDUCATION-FALL-2023-UPDATE-TIME-FOR-CLASS-STUDY.pdf
Citation:
> [!note] Citation
> ## Tyton Partners 2023
> Tyton Partners. “Generative AI in Higher Education: Fall 2023 Update of Time For Class Study,” 2023. https://tytonpartners.com/app/uploads/2023/10/GenAI-IN-HIGHER-EDUCATION-FALL-2023-UPDATE-TIME-FOR-CLASS-STUDY.pdf

# Summary
Study was done in partnership with Turnitin

49% of students use Gen AI

Use cases:
![[Pasted image 20241027204341.png]]

> 2% of Faculty Non-users and 6% of Faculty AI users permit GenAI to be used by students for writing large parts of assignments, while 27% of AI-using students report leveraging AI for this writing use case;
> 
> nearly half of all AI-using students are leveraging tools to write small parts of assignments despite 9% of non-using faculty and 21% of AI-using faculty permitting it 

![[Pasted image 20241027204527.png]]

---

# Source Idk Global Education Insights Report 2024

Title: Global Educators Report Concern About Student Mental Health and Challenges Outside of School, New Study Finds
Link: https://www.mheducation.com/news-insights/press-releases/2024-global-education-insights-report.html
Citation:
> [!note] Citation
> ## McGraw Hill 2024
> “Global Educators Report Concern About Student Mental Health and Challenges Outside of School, New Study Finds,” April 16, 2024. https://www.mheducation.com/news-insights/press-releases/2024-global-education-insights-report.html.

# Summary
41% of educators across all six regions believe AI has had a mostly positive impact on educational outcomes, compared to 19% who believe its impact has been mostly negative.

32% of educators are already using GenAI, which increases to 63% when including those who have either used or are expecting to use it in the next year. 80% have either already used GenAI or are expecting to use it at some point in the future.

48% of educators say they would mostly or completely trust the accuracy of information students get from GenAI chatbots and 48% say they only slightly trust it or not trust it at all, showing a dramatic split in sentiment.

The top two benefits of AI that educators believe will have a positive impact on education were: reducing time spent by them on administrative tasks (65%) and the ability to personalize learning experiences of each student (63%).

However, educators also identified areas of concern around the use of AI, including negative effects on academic integrity (32%), critical thinking (31%), memory retention (30%), and social skills and relationships (29%). Among US Higher Ed educators, the group that perceived AI most negatively, the areas in which the perceived negative impact was most strong were academic integrity (68%), critical thinking (62%) and "social skills/relationship" (58%).

---

# Source Idk Offering LLMs in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances

Title: The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances
URL: https://arxiv.org/abs/2407.09975
Citation:
> [!info] Citation
> ## Nie et al. 2024
> 
> Nie, Allen, Yash Chandak, Miroslav Suzara, Malika Ali, Juliette Woodrow, Matt Peng, Mehran Sahami, Emma Brunskill, and Chris Piech. “The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances.” arXiv, April 25, 2024. https://doi.org/10.48550/arXiv.2407.09975.

# Abstract

Large language models (LLMs) are quickly being adopted in a wide range of learning experiences, especially via ubiquitous and broadly accessible chat interfaces like ChatGPT and Copilot. This type of interface is readily available to students and teachers around the world, yet relatively little research has been done to assess the impact of such generic tools on student learning. Coding education is an interesting test case, both because LLMs have strong performance on coding tasks, and because LLM-powered support tools are rapidly becoming part of the workflow of professional software engineers. To help understand the impact of generic LLM use on coding education, we conducted a large-scale randomized control trial with 5,831 students from 146 countries in an online coding class in which we provided some students with access to a chat interface with GPT-4. We estimate positive benefits on exam performance for adopters, the students who used the tool, but over all students, the advertisement of GPT-4 led to a significant average decrease in exam participation. We observe similar decreases in other forms of course engagement. However, this decrease is modulated by the student's country of origin. Offering access to LLMs to students from low human development index countries increased their exam participation rate on average. Our results suggest there may be promising benefits to using LLMs in an introductory coding class, but also potential harms for engagement, which makes their longer term impact on student success unclear. Our work highlights the need for additional investigations to help understand the potential impact of future adoption and integration of LLMs into classrooms.

# Notes

We found that only 44.1% of the students in the experiment group took the diagnostic exam, compared to 48.5% of the students in the control group who took the exam

Surprisingly, the disengagement trend reversed for the students who are from the low HDI countries: the exam participation in the experiment group is notably higher at 42.3% compared to participation in the control group, at 27.5%

We estimate adopters have a 6.8 percentage point average treatment effect improvement in their exam scores due to using the provided LLM.



---

# Source Idk Students’ Use of Large Language Models in Engineering Education

Title: Students’ Use of Large Language Models in Engineering Education: A Case Study on Technology Acceptance, Perceptions, Efficacy, and Detection Chances.
Link: https://www.sciencedirect.com/science/article/pii/S2666920X23000516?via%3Dihub#sec3
Citation:
> [!note] Citation
> ## Bernabei et al. 2023
> Bernabei, Margherita, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. “Students’ Use of Large Language Models in Engineering Education: A Case Study on Technology Acceptance, Perceptions, Efficacy, and Detection Chances.” _Computers and Education: Artificial Intelligence_ 5 (October 5, 2023): 100172. https://doi.org/10.1016/j.caeai.2023.100172.

# Abstract
- Exploration of LLMs, like ChatGPT, in engineering education and assessment of students' acceptance, perceptions, efficacy, and detection chances.
- Engineering students produce high-quality essays with LLM assistance, maintaining academic performance.
- LLM assistance benefits the students' understanding of the topics.
- Thirteen LLM detectors tested achieved unsatisfactory results, and limitations.
- LLMs availability emphasizes the importance of developing students' critical thinking and problem-solving skills.

None of the tested detectors could be deemed reliable in identifying text generated by AI, thus it is advisable for teachers not to depend solely on a detector for identifying text generated using LLM.

---

# Source Pro Tutor CoPilot

Title: Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise
URL: https://arxiv.org/abs/2410.03017
Citation:
> [!note] Citation
> ## Wang et al. 2024
> Wang, Rose E., Ana T. Ribeiro, Carly D. Robinson, Susanna Loeb, and Dora Demszky. “Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise.” arXiv, October 3, 2024. https://doi.org/10.48550/arXiv.2410.03017.

# Abstract
Generative AI, particularly Language Models (LMs), has the potential to transform real-world domains with societal impact, particularly where access to experts is limited. For example, in education, training novice educators with expert guidance is important for effectiveness but expensive, creating significant barriers to improving education quality at scale. This challenge disproportionately harms students from under-served communities, who stand to gain the most from high-quality education. We introduce Tutor CoPilot, a novel Human-AI approach that leverages a model of expert thinking to provide expert-like guidance to tutors as they tutor. This study is the first randomized controlled trial of a Human-AI system in live tutoring, involving 900 tutors and 1,800 K-12 students from historically under-served communities. Following a preregistered analysis plan, we find that **students working with tutors that have access to Tutor CoPilot are 4 percentage points (p.p.) more likely to master topics (p<0.01). Notably, students of lower-rated tutors experienced the greatest benefit, improving mastery by 9 p.p**. We find that Tutor CoPilot costs only $20 per-tutor annually. We analyze 550,000+ messages using classifiers to identify pedagogical strategies, and find that tutors with access to Tutor CoPilot are more likely to use high-quality strategies to foster student understanding (e.g., asking guiding questions) and less likely to give away the answer to the student. Tutor interviews highlight how Tutor CoPilot's guidance helps tutors to respond to student needs, though they flag issues in Tutor CoPilot, such as generating suggestions that are not grade-level appropriate. Altogether, our study of Tutor CoPilot demonstrates how Human-AI systems can scale expertise in real-world domains, bridge gaps in skills and create a future where high-quality education is accessible to all students.


---

# Source Pro AI Math Tutor in Ghana

Name: Effective and Scalable Math Support: Evidence on the Impact of an AI- Tutor on Math Achievement in Ghana
Link: https://arxiv.org/abs/2402.09809
Citation:
> [!info] Citation
> 
> ## Henkel et al. 2024
> 
> Henkel, Owen, Hannah Horne-Robinson, Nessie Kozhakhmetova, and Amanda Lee. “Effective and Scalable Math Support: Evidence on the Impact of an AI- Tutor on Math Achievement in Ghana.” arXiv, May 5, 2024. https://doi.org/10.48550/arXiv.2402.09809.

# Abstract

This study is a preliminary evaluation of the impact of receiving extra math instruction provided by Rori, an AI-powered math tutor accessible via WhatsApp, on the math performance of approximately 500 students in Ghana. Students assigned to both the control and treatment groups continued their normal classes with identical curricula and classroom hours. Students in the treatment group were given access to a phone for one hour a week during their study hall period and were allowed to use Rori to independently study math. All other aspects of the groups’ in-school experience were the same. We find that **the math growth scores were substantially higher for the treatment group and statistically significant (p < 0.001)**. The effect size of 0.36 is considered large in the context of educational interventions: approximately equivalent to an extra year of learning. Importantly, Rori works on basic mobile devices connected to low-bandwidth data networks, and the marginal cost of providing Rori is approximately $5 per student, making it a potentially scalable intervention in the context of LMICs’ education systems. While the results should be interpreted judiciously, as they only report on year 1 of the intervention, they do suggest that chat-based tutoring solutions leveraging AI could offer a cost-effective and operationally efficient approach to enhancing learning outcomes for millions of students globally.

# Notes

To assess the impact of using Rori on learning, growth scores were computed by sub-
tracting baseline raw scores, the number of questions answered correctly, from endline
raw scores for each student who completed both tests. An independent samples t-test
between the control (M = 2.12, SD = 6.30) and the treatment group (M = 5.13, SD =
7.03) revealed that the **3.01 difference in growth scores** was highly statistically signifi-
cant (p < 0.001).

The assessment consisted of **35 questions**, each worth one point, with a mixture of multiple-choice and open-response questions covering numeracy and algebra skills from grades 3 to 5 on the Global Proficiency Framework.

3/35 = 8.5%

The calculated effect size between the baseline and endline, expressed as Cohen's d, was found to be 0.36. This effect size would be considered a moderate to large effect size in educational re-
search. Hattie et al. would categorize 0.29 as moderate, and similar to the magnitude of the effect of a good teacher . Whereas Kraft proposes argued that educational interventions with an 0.20 SD of over should be considered as large.

---

# Source Pro Artificial Intelligence, Scientific Discovery, and Product Innovation

Title: Artificial Intelligence, Scientific Discovery, and Product Innovation
URL: https://conference.nber.org/conf_papers/f210475.pdf
Citation:
> [!info] Citation
> ## Toner-Rodgers 2024
> Toner-Rodgers, Aidan. “Artificial Intelligence, Scientific Discovery, and Product Innovation,” November 4, 2024. https://conference.nber.org/conf_papers/f210475.pdf.

# Abstract
This paper studies the impact of artificial intelligence on innovation, exploiting the
randomized introduction of a new materials discovery technology to 1,018 scientists in
the R&D lab of a large U.S. firm. **AI-assisted researchers discover 44% more materials,**
**resulting in a 39% increase in patent filings and a 17% rise in downstream product in-**
**novation**. These compounds possess more novel chemical structures and lead to more
radical inventions. However, the technology has strikingly disparate effects across
the productivity distribution: while the bottom third of scientists see little benefit,
the output of top researchers nearly doubles. Investigating the mechanisms behind
these results, I show that AI automates 57% of “idea-generation” tasks, reallocating
researchers to the new task of evaluating model-produced candidate materials. Top
scientists leverage their domain knowledge to prioritize promising AI suggestions,
while others waste significant resources testing false positives. Together, these findings
demonstrate the potential of AI-augmented research and highlight the complemen-
tarity between algorithms and expertise in the innovative process. Survey evidence
reveals that these gains come at a cost, however, as 82% of scientists report reduced
satisfaction with their work due to decreased creativity and skill underutilization.

---

# Source Pro Backwards Planning with Generative AI

Title: Backwards Planning with Generative AI: Case Study Evidence from US K12 Teachers
Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4924786
Citation:
> [!note] Citation
> ## Keppler et al. 2024
> Keppler, Samantha, Wichinpong Park Sinchaisri, and Clare Snyder. “Backwards Planning with Generative AI: Case Study Evidence from US K12 Teachers.” SSRN Scholarly Paper. Rochester, NY: Social Science Research Network, August 13, 2024. https://doi.org/10.2139/ssrn.4924786.
# Abstract

Backward planning is an effective and efficient operational process when working towards a goal: work backward from the desired outcome to figure out the steps needed to accomplish them in the time allowed. While many organizations and workers might use it, backward planning is a universal practice among US K12 teachers. The emergence of generative AI has stimulated many conversations about its impact on teacher work, but it is still unclear if and how generative AI fits within the backward planning approach adopted by most every teacher. Given backward planning is standard workflow process in K12 education, we ask: How are teachers using generative AI to support their teaching work? Our methodology is a case study of 24 US public school teachers, sampled to vary by subject area and grade level, during the 2023-2024 school year. We conduct interviews, observations, and surveys at different points in time to understand their evolving generative AI use. In fall 2023, all teachers were novice users or had never tried generative AI. By spring 2024, the teachers separate into three distinct groups: (1) those who seek generative AI input (i.e., thoughts or ideas about learning plans) and output (i.e., quizzes, worksheets), (2) those who only seek generative AI outputs, and (3) those not using generative AI. **The teachers in the first group-but not the second group-report productivity gains in terms of workload and work quality**. Our findings have implications for understanding how to integrate generative AI into backward, goal-oriented workflows.



---

# Source Pro ChatGPT Used by Teachers More Than Students, New Survey from Walton Family Foundation Finds

Title: ChatGPT Used by Teachers More Than Students, New Survey from Walton Family Foundation Finds
Link: https://www.waltonfamilyfoundation.org/chatgpt-used-by-teachers-more-than-students-new-survey-from-walton-family-foundation-finds
Citation:
> [!note] Citation
> ## Walton Family Foundation 2023
> Walton Family Foundation. “ChatGPT Used by Teachers More Than Students, New Survey from Walton Family Foundation Finds,” March 1, 2023. https://www.waltonfamilyfoundation.org/chatgpt-used-by-teachers-more-than-students-new-survey-from-walton-family-foundation-finds.

# Summary
Key findings include:

- Within two months of its introduction, a 51% majority of teachers reported using ChatGPT, with **40% using it at least once a week**, and 53% expecting to use it more this year. Just 22% of students said they use the technology on a weekly basis or more.
- **Black (69%) and Latino (69%) teachers reported a higher rate of usage.**    
- Teachers are nearly four times more likely to have allowed students to use ChatGPT (38%) than caught them using it without their permission (10%). Only 15% of students admit to using the program without their teachers’ permission. 
- The majority of students (63%) and teachers (72%) agree that “ChatGPT is just another example of why we can’t keep doing things the old way for schools in the modern world.”
- Most students think it can help them become better students (68%) and help them learn faster (75%). Teachers agree: 73% say ChatGPT can help their students learn more.

“Educators are innovators,” said Romy Drucker, Director of the Education Program at the Walton Family Foundation. “They recognize the urgency of this moment and want to use every tool at their disposal to meet each students’ unique needs.”

Nearly all teachers (91%) and students (87%) believe technology is important to get students back on track from recent academic losses. The most recent National Assessment of Educational Progress results reveal the pandemic erased nearly two decades of gains in math and reading literacy, with students living in low-income communities experiencing the biggest drops in test scores. Pandemic learning loss is predicted to result in a $14.2 trillion decrease in GDP.

In Illinois teacher Diego Marin’s 8th grade math class, ChatGPT helps provide differentiated support for students at all levels. “ChatGPT is like a personalized 1:1 tutor that is super valuable for students, especially in the math space,” said Marin.

Most teachers (71%) and students (65%) agree that “ChatGPT will be an essential tool for students' success in college and the workplace,” as many school districts are banning or limiting access to the technology in schools.

“As a young person, I see my future as in some ways limited by computers and algorithms, knowing there are jobs [that can be] replaced by automation,” said Kentucky high school junior Zachary Clifton. “But this is an algorithm I can take advantage of and use it to advance myself … It’s something I can use responsibly and will use responsibly moving forward.”

The survey, which highlights perspectives from more than 2,000 K-12 teachers and students ages 12-17, offers a stark contrast from current debates about ChatGPT in schools. The majority of students (68%) and teachers (73%) agree that ChatGPT can help them learn more at a faster rate. According to the survey, 64% of teachers plan to implement the technology more often, from lesson planning, to creating new ideas, to using it as part of curriculum.

Click here to read the report

**About the Survey**

Impact Research surveyed 1,002 K-12 teachers and 1,000 students ages 12-17 nationwide between February 2-7, 2023. Interviews were conducted online. The samples were weighted to align with demographic estimates from the U.S. Census Bureau's American Community Survey (2021 5-year data).

---

# Source Pro Cheating in the age of generative AI A high school survey study of cheating behaviors before and after the release of ChatGPT

Title: Cheating in the age of generative AI: A high school survey study of cheating behaviors before and after the release of ChatGPT
Link: https://www.sciencedirect.com/science/article/pii/S2666920X24000560?via%3Dihub#abs0010
Citation:
> [!note] Citation
> ## Lee et al. 2024
> Lee, Victor R., Denise Pope, Sarah Miles, and Rosalía C. Zárate. “Cheating in the Age of Generative AI: A High School Survey Study of Cheating Behaviors before and after the Release of ChatGPT.” _Computers and Education: Artificial Intelligence_ 7 (June 14, 2024): 100253. https://doi.org/10.1016/j.caeai.2024.100253.
# Abstract
The public release of ChatGPT and other generative AI chatbot technologies has been accompanied by questions about how academic integrity and student cheating behaviors will be impacted. We analyzed anonymous survey data from three high schools to see if self-reported cheating numbers changed following the introduction of ChatGPT and similar technologies. This survey data set is unique in that data on cheating had been collected with this set of schools both before and after November 2022, when ChatGPT was publicly released and drew attention to these educational concerns. The results suggested that **cheating behaviors remained relatively stable after the introduction of this current generation of generative AI chatbot technology**. However, some changes in reported behaviors differed depending on the type of cheating (social cheating, AI-related cheating, etc.). Additional survey questions about high school students’ AI chatbot usage and the perceived allowability of such technology revealed mixed opinions on the acceptability of using AI for various academic-related tasks. Most students did not think that using a chatbot to produce an entire paper or complete an entire assignment should be allowable. However, there was support for using AI chatbots to help students to start on assignments and papers and to help explain new concepts to them.

## 6. Results

### 6.1. Responses on cheating scale

Across schools for the years analyzed, between 59.9% and 69.5% reported engaging in at least one academically dishonest behavior in the previous month. These numbers were relatively consistent for Private High (2019: 61.3%, 2022: 62.4%, 2023: 59.9%). The range was higher for Charter High (2019: 82.7%, 2022: 64.0%, 2023: 64.4%) and Public High (2019: 69.5%, 2023: 62.7%). Conner, Galloway, and Pope (2009) would be the first year in which responses could be provided after the rollout of ChatGPT and other similarly powerful AI chatbots, it is worth noting that **the overall percentages from responses stayed about the same or decreased overall relative to prior years** (i.e., Public High 2022; 2023; Charter High 2019; 2023). Responses to cheating items are provided for the three schools in Table 3, Table 4, Table 5

#### 6.1.1. Cheating scale items without significant difference

Across all three schools, five items on the cheating scale (C37, C39, C40, C44, C45; refer to Table 3, Table 4, Table 5 showed no significant difference compared to 2023, indicating no major changes in reported behaviors. Pertinent to AI-generated writing, there were no significant changes for items C39 (paraphrase or copy a few sentences from a written source without attribution) and C45 (turning in work done by someone else). It may be that students do not consider AI technology a written source, the sentence level is not where paraphrasing or copying happens, or that students did not consider AI to be ‘someone else’.

With respect to potentially using an AI chatbot as an aid during an assessment, the lack of significant differences for C40 suggests there has not been a major overall proportional change driven by the introduction of AI.

#### 6.1.3. Cheating scale items connected to AI with some significant differences

As noted above, there were five items with no significant differences in any comparison with 2023. That included items C39 and C45, which could be pertinent to using AI for providing text to use in writing assignments. Two other items seemed to have relevance to AI: C41 and C42. C41 was the most direct question about artificial intelligence use. Note that the language of C41 changed in 2023 as AI was not as prominent of a concern until the end of 2022. The former language involved asking about use of a device in an unauthorized way during an assessment. The newer language explicitly named artificial intelligence and broadened to include assessments, school assignments, and homework. This newer language was used as it was unclear how students recognized chatbot technology and if its use was for them bound to mobile devices. Moreover, with heightened public concern around chatbot technology, explicitly naming various writing products beyond assessments was deemed appropriate in order to directly consider several different types of assigned writing that students may be asked to do for school. This showed a significant difference for Charter High (2019–2023: χ2 = 10.197 df = 1 p = 0.001, 2022–2023: χ2 = 29.882 df = 1 p < 0.001) and Public High (2022–2023 χ2 = 15.886 df = 1 p < 0.001), but not for Private High when a Bonferroni correction is applied (2019–2023: χ2 = 4.316 df = 1 p = 0.038, 2022–2023: (χ2 = 0.617 df = 1 p = 0.432).

## Debate block
An 2024 study conducted by a Stanford University researcher found that there were no noticeable differences in cheating caused by the release of AI when comparing surveys about cheating before and after the release of AI, and that overall cheating even slightly decreased throughout this period. There were also no statistically significant differences in the prevalence of cheating with technology before and after AI was introduced. 

---

# Source Pro Generative AI Is Set to Shake Up Education

Title: Generative AI Is Set to Shake Up Education
Link: https://www.morganstanley.com/ideas/generative-ai-education-outlook
Citation:
> [!note] Citation
> ## Morgan Stanley 2023
> Morgan Stanley. “Generative AI Is Set to Shake Up Education,” December 22, 2023. https://www.morganstanley.com/ideas/generative-ai-education-outlook.

# Summary
“Generative AI could actually enhance the overall learning experience, by cutting down on administrative work and maximizing human interaction, as well as by reskilling or upskilling workers whose jobs have been affected by the technology,” says Brenda Duverce, an analyst on the Morgan Stanley Sustainability Research team. “**These and other efficiencies could bring $200 billion in value to the global education sector by 2025**, which could ultimately translate to higher revenue and lower costs for the best-positioned EdTech companies.”


---

# Source Pro GPT-4 as a Homework Tutor can Improve Student Engagement and Learning Outcomes

Title: GPT-4 as a Homework Tutor can Improve Student Engagement and Learning Outcomes
Link: https://arxiv.org/abs/2409.15981
Citation:
> [!note] Citation
> ## Vanzo, Chowdhury and Sachan 2024
> Vanzo, Alessandro, Sankalan Pal Chowdhury, and Mrinmaya Sachan. “GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes.” arXiv, September 24, 2024. https://doi.org/10.48550/arXiv.2409.15981.

# Abstract
This work contributes to the scarce empirical literature on LLM-based interactive homework in real-world educational settings and offers a practical, scalable solution for improving homework in schools. Homework is an important part of education in schools across the world, but in order to maximize benefit, it needs to be accompanied with feedback and followup questions. We developed a prompting strategy that enables GPT-4 to conduct interactive homework sessions for high-school students learning English as a second language. Our strategy requires minimal efforts in content preparation, one of the key challenges of alternatives like home tutors or ITSs. We carried out a Randomized Controlled Trial (RCT) in four high-school classes, replacing traditional homework with GPT-4 homework sessions for the treatment group. We observed significant improvements in learning outcomes, specifically a greater gain in grammar, and student engagement. In addition, students reported high levels of satisfaction with the system and wanted to continue using it after the end of the RCT.

The tutor bot helped improve grades by 4.3 percentage points for students in the equivalent of 11th grade, with an effect size of 0.6. 100% of students who used the homework tutor bot wanted to use it for their next high school year. 

---

# Source Pro Interactive, personalized computer-based teacher professional development program on student performance

Title: The impact of an interactive, personalized computer-based teacher professional development program on student performance: A randomized controlled trial
Link: https://www.sciencedirect.com/science/article/pii/S0360131523002403
Citation:
> [!info] Citation
> ## Copur-Gencturk et al. 2024
> Copur-Gencturk, Yasemin, Jingxian Li, Allan S. Cohen, and Chandra Hawley Orrill. “The Impact of an Interactive, Personalized Computer-Based Teacher Professional Development Program on Student Performance: A Randomized Controlled Trial.” _Computers & Education_ 210 (March 1, 2024): 104963. https://doi.org/10.1016/j.compedu.2023.104963.

# Abstract
Scholars and practitioners have called for personalized and widely accessible professional development (PD) for teachers. Yet, a long-standing tension between customizing support and increasing access to such support has hindered the scale-up of high-quality PD for individual teachers. This study addresses this challenge by developing a computerized program for middle school mathematics teachers that provides frequent opportunities for teachers to interact with and obtain personalized and real-time feedback from a virtual facilitator based on natural language processing. Based on the data collected from 1727 middle school students in an experiment in which the teachers of these students were randomly assigned to the program or the business-as-usual condition (i.e., the control group), we found that **the program had a statistically significant impact on students’ mathematics performance**. These results demonstrate the potential of incorporating an automated, interactive feedback tool supported by artificial intelligence to create effective, scalable teacher PD.

On average, students of teachers in the treatment group scored 0.56 scale score points on the posttest, whereas students of teachers in the control group scored an average of 0.52 scale score points when we adjusted for students' grade and their individual and class-average baseline test scores.

The study found that an 11 hour AI program helping teachers improve their teaching ability increased student scores by 4 percentage points relative to control, even after adjusting for confounders. 

---

# Source Pro Kabakoo

Title: Impact of Kabakoo Academies
Link: https://www.kabakoo.africa/impact
Citation:
> [!note] Citation
> ## Kabakoo 2024
> “Impact of Kabakoo Academies | Success at Kabakoo Academies | Own Your Future, Shape Africa!” Accessed November 2, 2024. https://www.kabakoo.africa/impact.

# Summary
## **Tracking impact Post-training**

The long-term impact of Kabakoo’s training programs is evident. Our recent post-training assessments highlight several key areas of growth :

1. Treatment group learners consolidated their learning habits after training. **They achieved an average score of 2.1 at six months and 1.9 at 18 months post-training, compared with 1.5 for the control group**. This shows that Kabakoo learners maintain a long-term learning mindset.
2. Six months after training, 42% of learners received orders or obtained jobs related to their training, 65% of which were paid. At 18 months, this figure was at 46%, with 42% of opportunities being paid. These results illustrate the direct impact of training on the creation of professional opportunities.
3. Learners in the treatment group saw a significant increase in their income. Eighteen months after training, they reached an average category of around 120,000 FCFA, compared with around 70,000 FCFA for the control group - **an increase of 71%**. This demonstrates a considerable positive economic impact.
4. After 18 months, the NPS stood at 83, indicating that learners would strongly recommend the training to others for its impact.

Among the learners of our 2020 batches, the incidence of a _growth mindset increases by 105%_ and _learners’ self-confidence increases by 47%_. Moreover, 90% of our learners consider that their personal and professional situation has improved as a result of the Kabakoo program.

Our highdigenous model allows us to train youths from different educational backgrounds without diploma prerequisites. _22% of our learners didn’t finish high-school. Already 30% of our learners are women_, a significant share for tech-oriented education.

![[Source Pro Role of AI in Education 4.0#Kabakoo]]

# Debate block


---

# Source Pro Learning Progress with AI-Driven Tutoring

Title: Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring
Link: https://arxiv.org/abs/2403.14642

> [!info] **Citation**
> ## Möller et al. 2024
>
> Möller, Moritz, Gargi Nirmal, Dario Fabietti, Quintus Stierstorfer, Mark Zakhvatkin, Holger Sommerfeld, and Sven Schütt. “Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring.” arXiv, February 21, 2024. https://doi.org/10.48550/arXiv.2403.14642.

# Abstract
 Generative AI is expected to have a vast, positive impact on education; however, at present, this potential has not yet been demonstrated at scale at university level. In this study, we present first evidence that generative AI can increase the speed of learning substantially in university students. We tested whether using the AI-powered teaching assistant Syntea affected the speed of learning of hundreds of distance learning students across more than 40 courses at the IU International University of Applied Sciences. Our analysis suggests that **using Syntea reduced their study time substantially--by about 27% on average--** in the third month after the release of Syntea. Taken together, the magnitude of the effect and the scalability of the approach implicate generative AI as a key lever to significantly improve and accelerate learning by personalisation.

1 / (1 - 23%) = 137%

Students studied 37% more efficiently with the help of an AI compared to people who did not use AI. 

Our results suggest that using Syntea (in this case represented by the exam training feature) has helped students to gain an additional uplift in study progress of 46 percent-points relative to the control group. Translated into study duration ratios, this corresponds to a reduction from 81% relative to the control group to 59%, i.e. by about 22 percent-points, or equivalently by 27% (see Figure 3 for a visualisation of this result). While there might be other explanations for the data presented above, the precise temporal alignment of the effect supports this hypothesis.

# Notes

The group that used AI was 45% faster at completing the curriculum compared to the group that did not use AI. 

---

# Source Pro Merlyn

Title: Third-party Research Confirms That Merlyn Reduces Teacher Stress and Saves Time
Link: https://www.merlyn.org/blog/3rd-party-research-confirms-that-merlyn-reduces-teacher-stress-and-saves-time
Citation:
> [!note] Citation
> ## Merlyn, 2024
> “Third-Party Research Confirms That Merlyn Reduces Teacher Stress and Saves Time.” Accessed October 25, 2024. https://www.merlyn.org/blog/3rd-party-research-confirms-that-merlyn-reduces-teacher-stress-and-saves-time#contact.

# Summary

What if you had a tool that in a matter of weeks could reduce work-related stress by almost 15%?

Merlyn cut technostress by 14% in seven weeks

The UCI research found that 61% of teachers who used Merlyn reported an overall reduction of technology-related stress after just seven weeks.

Drs. Peppler and Schindler found that 51% of Symphony Classroom teachers reported an increase in teaching time savings and efficiency after seven weeks of use. Specifically, the Symphony Classroom teachers reported spending significantly less time on administrative tasks.

![[Pasted image 20241025111040.png]]
Merlyn teachers had 16 percentage points of more time on teaching, 3 percentage points less time on managing technology, and 6 percentage points less time on administrative tasks


---

# Source Pro Professor tailored AI tutor to physics course

Title: Professor tailored AI tutor to physics course. Engagement doubled.
URL: https://news.harvard.edu/gazette/story/2024/09/professor-tailored-ai-tutor-to-physics-course-engagement-doubled/
Citation:
> [!note] Citation
> ## Manning 2024
> Manning, Anne. “Professor Tailored AI Tutor to Physics Course. Engagement Doubled.” Harvard Gazette, September 5, 2024. https://news.harvard.edu/gazette/story/2024/09/professor-tailored-ai-tutor-to-physics-course-engagement-doubled/.

# Summary

Think of a typical college physics course: brisk notetaking, homework struggles, studying for tough exams. Now imagine access to a tutor who answers questions at any hour, never tires, and never judges. Might you learn more? Maybe even twice as much?

That’s the unexpected takeaway from a Harvard study examining learning outcomes for students in a large, popular physics course who worked with a custom-designed artificial intelligence chatbot last fall. When compared with a more typical “active learning” classroom setting in which students learn as a group from a human instructor, the AI-supported version proved to be surprisingly more effective.

> [!quote]
> Our findings provide clarity; here we show that students learn more than twice as much in less time with an AI tutor compared to an active learning classroom, while also being more engaged and motivated.
> -From the study at https://www.researchsquare.com/article/rs-4243877/v1

> [!quote]
> Students in the AI group exhibited a higher median (M) post score (M = 4.5, N = 142) compared to those in the active lecture group (M = 3.5, N = 174). The learning gains for students, relative to the pre-test baseline (M = 2.75, N = 316), in the AI-tutored group were over double those for students in the active lecture group.

4.5 - 2.75 = 1.75
3.5 - 2.75 = 0.75
1.75/0.75 = 233%

> [!quote]
> Students rated their level of agreement on a 5-point Likert scale, with 1 representing “strongly disagree” and 5 representing “strongly agree.” 
> 
> With the first statement, “I felt engaged (while interacting with the AI tutor) / (while in lecture),” the students in the AI group agreed more strongly (Mean = 4.1, SD = 0.98) than those in the active lecture (Mean = 3.6, SD = 0.92), t(311) = -4.5, _p_ < 0.0001. 
> 
> Likewise, with the second statement, “I felt motivated when working on a difficult question,” students in the AI group agreed more strongly (Mean = 3.4, SD = 1.0) than those in the active lecture (Mean = 3.1, SD = 0.86), t(311) = -3.4, _p_ < 0.001. 
> 
> Students’ average level of agreement with the remaining two statements (“I enjoyed the class session today” and “I feel confident that, with enough effort, I could learn difficult physics concepts”) were not statistically significantly different between the two groups.

> [!quote]
> 70% of students in the AI group spent less than 60 minutes on task, while 30% spent more than 60 minutes on task. The median time on task for students in the AI group was 49 minutes.

---

# Source Pro Relationship between student interaction with GAI and learning achievement

Name: The relationship between student interaction with generative artificial intelligence and learning achievement: serial mediating roles of self-efficacy and cognitive engagement
Link: https://doi.org/10.3389/fpsyg.2023.1285392

> [!info] Citation
> ## Liang et. al 2023
> 
> Liang, Jing, Lili Wang, Jia Luo, Yufei Yan, and Chao Fan. “The Relationship between Student Interaction with Generative Artificial Intelligence and Learning Achievement: Serial Mediating Roles of Self-Efficacy and Cognitive Engagement.” _Frontiers in Psychology_ 14 (December 22, 2023). https://doi.org/10.3389/fpsyg.2023.1285392.
# Abstract

Generative artificial intelligence (GAI) shocked the world with its unprecedented ability and raised significant tensions in the education field. Educators inevitably transition to an educational future that embraces GAI rather than shuns it. Understanding the mechanism between students interacting with GAI tools and their achievement is important for educators and schools, but relevant empirical evidence is relatively lacking. Due to the characteristics of personalization and real-time interactivity of GAI tools, we propose that the students–GAI interaction would affect their learning achievement through serial mediators of self-efficacy and cognitive engagement. Based on questionnaire surveys that include 389 participants as the objective, this study finds that: (1) in total, **there is a significantly positive relationship between student–GAI interaction and learning achievement**. (2) This positive relationship is mediated by self-efficacy, with a significant mediation effect value of 0.015. (3) Cognitive engagement also acts as a mediator in the mechanism between the student–GAI interaction and learning achievement, evidenced by a significant and relatively strong mediating effect value of 0.046. (4) Self-efficacy and cognitive engagement in series mediate this positive association, with a serial mediating effect value of 0.011, which is relatively small in comparison but also shows significance. In addition, the propensity score matching (PSM) method is applied to alleviate self-selection bias, reinforcing the validity of the results. The findings offer empirical evidence for the incorporation of GAI in teaching and learning.

---

# Source Pro Role of AI in Education 4.0

Title: Shaping the Future of Learning: The Role of AI in Education 4.0
Link: https://www.weforum.org/publications/shaping-the-future-of-learning-the-role-of-ai-in-education-4-0/
Citation: 
> [!note] Citation
> ## World Economic Forum 2024
> World Economic Forum. “Shaping the Future of Learning: The Role of AI in Education 4.0,” April 28, 2024. https://www.weforum.org/publications/shaping-the-future-of-learning-the-role-of-ai-in-education-4-0/.

# Summary

In the United Kingdom, 42% of primary and secondary teachers used generative AI to aid with their schoolwork in November 2023, a significant increase from 17% in April 2023.

New developments in AI can provide an opportunity to redefine the nature and quality of work in education roles. Research by the World Economic Forum, produced in collaboration with Accenture, finds that **40% of all time spent on tasks could potentially be impacted by large language models** (LLMs). This applies to teaching as well: while some teaching tasks could potentially be automated by these new technologies, other tasks stand to be augmented or enhanced by LLMs (see Table 1).

Tasks with the most potential to be automated or replaced by LLMs are those that tend to be routine or repetitive. In the education sector, up to 20% of work time on clerical activities and administrative tasks, such as assessing attendance, enrolment and other forms of data analysis, could be automated. Tasks most likely to benefit from the augmentation potential of LLMs tend to emphasize analytical and problem-solving capacities. These tasks make up 8%-20% of work time spent on tasks in the education sector and include lesson planning and evaluating student performance

## Kabakoo
Kabakoo employs an AI-enabled virtual mentor to provide 24/7 support to learners. This virtual mentor offers guidance, resources and advice whenever needed, supplementing human mentorship. The AI mentor also provides personalized feedback on learners’ assignments. After submitting their selfie video on a specific module, learners receive a personalized response via WhatsApp. Recognizing the linguistic diversity in Mali, Kabakoo is working on developing an AI-powered model to provide training in Bambara, the most spoken language in the country. In applying AI to address language barriers, Kabakoo promotes personalization, accessibility and inclusivity. The use of gamified virtual tokens (Kabakooins) and cloud-based resources contributes to a dynamic and robust learning environment

The success of the programme is evidenced by a randomized control trial that resulted in a 23% increase in growth mindset among learners in a pilot conducted at Kabakoo. Kabakoo learners also report seeing a 44% increase in income six months after completing the programme.

## Letrus
Letrus focuses on personalized learning through AI, offering immediate feedback to students, real-time data for educators and monitoring tools for school managers. Teachers receive tailored recommendations for content and methodologies, which can be seamlessly integrated into the curriculum to nurture and enhance specific skills. This iterative process ensures a dynamic and responsive approach to literacy development, aligning closely with the evolving needs of each student as well as the entire class. School managers can monitor progress and gain immediate insights into improvement areas as well as emerging learning gaps that may benefit from targeted intervention through teacher-training initiatives or strategic adjustments to the curriculum.

In 2022 the programme achieved notable success in the public schools of Espirito Santo. Within five months of programme implementation, participating students achieved the second position in the national writing exams, a remarkable improvement compared to the eighth position attained by the control group. Letrus was subsequently designated as the official literacy development programme for high school students in the state. Espírito Santo emerged as the top-performing state in the writing component of the National Exam, exhibiting a performance delta five times the national average from 2021 to 2022

https://drive.google.com/file/d/16YCXSAJ7j06lk-bicz-zYUd37hks-kB_/view

Students participated in 32% more writing activities, and discussed with teachers regarding writing 35% more. 

## Ceibal
AI lessons are utilized to help students understand the inner workings of machine learning models and gain insights into the use of data, as well as the potential biases present. The programme employs various evaluation tools, including learning tests, surveys and class observations. The programme’s aim is to foster the competencies of solving computational problems, data and information analysis, algorithms and procedures, as well as social transformation, acknowledging the integration of computers into our everyday lives.

Ceibal participates in the Bebras Competition, an international exam on computational thinking. A recent sample of Bebras exam results showed that students who participated in the programme significantly outperformed those who did not, with some differences observed in favour of girls. This community-driven initiative led to the integration of computational thinking competence into Uruguay’s 2023 educational reforms

## UAE AI Tutor Project
The AI tutor tailors lessons to the individual needs and learning styles of each student, ensuring that they receive the right level of challenge and support. It continually assesses student progress, identifying areas of improvement and providing targeted feedback and additional resources to help students overcome their challenges. The tutor can also provide support in multiple languages, ensuring that students from diverse linguistic backgrounds also have access to quality education. By automating certain teaching tasks and providing valuable insights into student progress, the UAE AI Tutor project aims to alleviate teacher workload, enabling them to focus on more strategic and interactive aspects of the learning experience. The platform also generates detailed reports for educators and parents, enabling them to monitor and support student progress effectively. Further, the AI tutor breaks up linear and time-consuming methods of feedback to provide real-time analytics to all stakeholders, including at the ministerial level, enabling more adaptive strategy development.

The project already showed improvements during the piloting stage in average grades and positive impact on students’ academic performance. It demonstrated a 10% increase in learning outcomes.
